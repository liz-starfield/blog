<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.13" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="alternate" hreflang="en-us" href="https://liz-in-tech.github.io/blog/posts/llm/015_fine_tune.html"><meta property="og:url" content="https://liz-in-tech.github.io/blog/zh/posts/llm/015_fine_tune.html"><meta property="og:site_name" content="Liz"><meta property="og:title" content="微调"><meta property="og:description" content="微调 模型微调流程 LoRA Llama-factory 基础开源模型 MoE 混合专家模型 RLHF 基于人类反馈的强化学习"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:locale:alternate" content="en-US"><meta property="og:updated_time" content="2024-11-13T05:26:25.000Z"><meta property="article:author" content="Liz"><meta property="article:tag" content="Fine-tuning"><meta property="article:published_time" content="2024-11-05T00:00:00.000Z"><meta property="article:modified_time" content="2024-11-13T05:26:25.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"微调","image":[""],"datePublished":"2024-11-05T00:00:00.000Z","dateModified":"2024-11-13T05:26:25.000Z","author":[{"@type":"Person","name":"Liz","url":"https://github.com/liz-in-tech"}]}</script><link rel="icon" herf="/blogger.png"><link rel="icon" href="/blog/blogger.png"><title>微调 | Liz</title><meta name="description" content="微调 模型微调流程 LoRA Llama-factory 基础开源模型 MoE 混合专家模型 RLHF 基于人类反馈的强化学习">
    <link rel="preload" href="/blog/assets/style-lMqD2uhz.css" as="style"><link rel="stylesheet" href="/blog/assets/style-lMqD2uhz.css">
    <link rel="modulepreload" href="/blog/assets/app-fX15qMK8.js"><link rel="modulepreload" href="/blog/assets/015_fine_tune.html-V8hUrR0F.js"><link rel="modulepreload" href="/blog/assets/015_fine_tune.html-a4VvWypD.js"><link rel="modulepreload" href="/blog/assets/015_switching_ffn_layer-fh4TiazV.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js">
    <link rel="prefetch" href="/blog/assets/index.html-YbPtte5_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-CGfhr1vY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUMOuem4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--TTjrkIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g4Nfr7z1.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-bitGHKd2.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-nrisQopy.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-9XtwFAwc.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-oji9upQP.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-xrin91s2.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-uTrDxa9X.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-SkR0eAcU.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-4RcS3hxb.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-_8stdYVV.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-eluz3bTT.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-kyWTqF2Z.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-CImz0KSx.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-1CqW55t5.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-TySaXNKY.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-D0EAMf5U.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-JrbwEhT3.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-XtD4OMNh.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-YW3F__H8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDCSnlc1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZYw6WxxA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OavE9BET.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-hE_T0u_5.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-iH0mq6XB.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-WyFhRqF6.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-YaT0PR6o.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-gL7Qg_J4.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-8B4QlsI8.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-hz6Q-DAA.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-3KMCwhrh.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-7gxKMp_3.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-hkr_5TZF.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-Akmj-Ub_.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-bXz0YlpJ.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-DdNZTAtu.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-wgiIiCcb.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-DCPUUxWe.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-AuK8xh4H.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wh_dBtOR.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-cxLWDy2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kf4JCRaf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RkA-insV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4kI_oqSd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WhuidxNt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OqGkeUA_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5GeN-sdD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-c4Rf4yh1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2r0jUs7o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BSKRXRQc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-KjTsJ0Hg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TteIwMx3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g00XXzrL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-YxbJgo4L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3T79Cy0i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A5tlQHan.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-04ff5e0O.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vgZ6rfFh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OmipPplE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E1KrJL6a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oPH9QkTj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cHRqZSs8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-74SU9ZTn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--iJiA8oX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oZPWb_Fc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FUIWSLsp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5ERWyusD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Zjn0JNqd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jcvPTrgB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9t2TsyuQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CcLVFNIv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVoYOOaL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V52ipvRm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9If_KW0o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LHukpLS7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-howjHe2f.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DeN_iOWx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cnlzR0a7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0P_c_pcU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dy_CcFmq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FzFytZ_p.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-2KSwV7xp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F1coElwg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ffflqCb9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-F8ZuLYgH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HeYWaFeL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xKYeJEc5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xB-iS7Ql.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OEUPqfTV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EE4iQI9m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-g1PUF_BG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nUBcs85a.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Y3la5Sf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wufIFDPM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bXZQIxRE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wd6ZkEHi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xlk0AXmC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-inUIEpZU.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-_n8JwNyO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ITIRDhEj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WKAt0hmJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Xu3yUfC_.js" as="script"><link rel="prefetch" href="/blog/assets/intro.html-ifgRg-_-.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-gl7jLolY.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-ue-JYtcw.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-aLt6R8zz.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html--pnOaPcH.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-QcbqR-TX.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-kgNzhRyB.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-WpTlUSJi.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html--MLpCsbx.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-XZa9e-3z.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-Z1KcjgQ9.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-esfdzXCO.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-HnUg9lsn.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-jVgNFbni.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-KLDs0ykV.js" as="script"><link rel="prefetch" href="/blog/assets/015_fine_tune.html-gb65TN9K.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-7k0blMP0.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-MuN8qhbJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-b8wmTqu5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_4KWlsb7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8wgqgON4.js" as="script"><link rel="prefetch" href="/blog/assets/001_langchain.html-clqyTpeI.js" as="script"><link rel="prefetch" href="/blog/assets/002_langchain_sourcecode.html-PL02i77s.js" as="script"><link rel="prefetch" href="/blog/assets/003_streamlit.html-wK9n401r.js" as="script"><link rel="prefetch" href="/blog/assets/004_transformer.html-PU8BqcCF.js" as="script"><link rel="prefetch" href="/blog/assets/005_llama.html-BNkLGETd.js" as="script"><link rel="prefetch" href="/blog/assets/006_llm_leaderboard.html-6eJaaLc8.js" as="script"><link rel="prefetch" href="/blog/assets/007_computer_use.html-FB-zXGX3.js" as="script"><link rel="prefetch" href="/blog/assets/008_rag_challenge.html-OllJX1KG.js" as="script"><link rel="prefetch" href="/blog/assets/009_llm_challenge.html-kqJujUnY.js" as="script"><link rel="prefetch" href="/blog/assets/010_rag_workflow.html-vvbe-bjh.js" as="script"><link rel="prefetch" href="/blog/assets/011_vector_database.html-8kWZIeev.js" as="script"><link rel="prefetch" href="/blog/assets/012_prompt_engineering.html-l-Z3fhCU.js" as="script"><link rel="prefetch" href="/blog/assets/013_optimizing_llm.html-YiVH1yKP.js" as="script"><link rel="prefetch" href="/blog/assets/014_rag_evaluation.html-1gLmV4mE.js" as="script"><link rel="prefetch" href="/blog/assets/016_multimodal.html-n2bFnv5f.js" as="script"><link rel="prefetch" href="/blog/assets/017_agent_and_multiagent.html-_JBbd2AS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BoRApbU5.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-ZU9cS0B6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sl0FN56h.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EcOE65ts.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--ZJ_JNBq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_J0bPqWE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ncUV39PW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_k_wX-UT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RHsM4WuN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UGtaLJ3L.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-a_PWKmZG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VWtWNafW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-R85-gMVG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_YikJXwn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Nka4KmE-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nfiZsTci.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4ejLTLHD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-u4RKdamB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5AWDGUVm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ytmwgyF3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GDAv-_jm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yWv2RdYs.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wBPvNigu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jBzp_zL9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-IBtH0Be2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qwx8sbtX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bi3tD-is.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8pgbINmJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4ifKv5Zu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-A3RF2lP7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-LgN73kc2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OkUWMXZ7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-93G8_Tsu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8ZPvmd_A.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BauYvXuh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_BtwD2xd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ABrlNsF8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vy0bdAAt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3NSBCsDn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Eu6iciWK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sDGwsm4R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kmCDGO6C.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jEGOn4DI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-b8fhjc7n.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nT8qzqrr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DNSaTVmx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oCArOS2T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-NUnSoiA7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tD0iMxfb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rSM1GJL0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m4hfbZ4_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eqmfbmRQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-p6G8Ege8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OVTmXc99.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Enu_CItk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HU3DKoVY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VzGOKS4I.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Vpjxx4nf.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-08_zHRDQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/zh/"><img class="vp-nav-logo" src="/blog/blogger.png" alt><!----><span class="vp-site-name hide-in-pad">Liz</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="首页" class="vp-link nav-link nav-link" href="/blog/zh/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>首页<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="项目" class="vp-link nav-link nav-link" href="/blog/zh/demo/"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>项目<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button type="button" class="dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="English" class="vp-link nav-link nav-link" href="/blog/posts/llm/015_fine_tune.html"><!---->English<!----></a></li><li class="dropdown-item"><a aria-label="简体中文" class="vp-link nav-link active nav-link active" href="/blog/zh/posts/llm/015_fine_tune.html"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>微调</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/liz-in-tech" target="_blank" rel="noopener noreferrer">Liz</a></span><span property="author" content="Liz"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-11-05T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 12 分钟</span><meta property="timeRequired" content="PT12M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">LLM</span><!--]--><meta property="articleSection" content="LLM"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag5 clickable" role="navigation">Fine-tuning</span><!--]--><meta property="keywords" content="Fine-tuning"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_1-微调-fine-tuning">1. 微调 Fine-tuning</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-1-指令微调-有监督微调">1.1. 指令微调/有监督微调</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_1-2-多任务微调-multi-tasking-ft">1.2. 多任务微调 Multi-tasking FT</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_2-模型微调流程">2. 模型微调流程</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_3-数据构造">3. 数据构造</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_4-微调策略分类">4. 微调策略分类</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-1-基于微调范围-全量微调和部分参数微调">4.1. 基于微调范围：全量微调和部分参数微调</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-2-基于任务-sft-rlhf-rlaif">4.2. 基于任务：SFT，RLHF，RLAIF</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-3-低资源微调">4.3. 低资源微调</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_4-4-deepspeed">4.4. deepspeed</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_5-lora-与-qlora">5. LoRA 与 QLoRA</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-1-lora">5.1. LoRA</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_5-2-qlora">5.2. QLoRA</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_6-微调实践">6. 微调实践</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-1-3个关键部分">6.1. 3个关键部分</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-2-微调高级设置">6.2. 微调高级设置</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-3-github-tloen-alpaca-lora">6.3. github: tloen/alpaca-lora</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-4-llama-factory">6.4. LLaMA-Factory</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_6-5-more">6.5. More</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_7-开源模型">7. 开源模型</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#_7-1-mistral-7b">7.1. Mistral-7B</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_8-混合专家模型-moe-mixture-of-experts">8. 混合专家模型 MoE，Mixture of Experts</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_9-rlhf-基于人类反馈的强化学习">9. RLHF 基于人类反馈的强化学习</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#_10-references">10. References</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="微调" tabindex="-1"><a class="header-anchor" href="#微调" aria-hidden="true">#</a> 微调</h1><ul><li>模型微调流程</li><li>LoRA</li><li>Llama-factory</li><li>基础开源模型</li><li>MoE 混合专家模型</li><li>RLHF 基于人类反馈的强化学习</li></ul><!-- more --><h2 id="_1-微调-fine-tuning" tabindex="-1"><a class="header-anchor" href="#_1-微调-fine-tuning" aria-hidden="true">#</a> 1. 微调 Fine-tuning</h2><ul><li>目标：放大所需能力同时，保持其他能力不变</li><li>价值：增强了相应的能力</li><li>问题：遗忘问题 catastrophic forgetting（有可能在其他能力上会有所下降） <ul><li>解决思路 <ul><li>思路1：不需要解决 <ul><li>其他能力不太看重，下降了也不会有太大影响</li></ul></li><li>思路2：使用更大的模型，其被影响的几率是比较小的，因为泛化能力更强</li><li>思路3：多任务微调 <ul><li>结合其他能力的数据</li><li>缺什么能力，补什么能力</li></ul></li></ul></li></ul></li></ul><h3 id="_1-1-指令微调-有监督微调" tabindex="-1"><a class="header-anchor" href="#_1-1-指令微调-有监督微调" aria-hidden="true">#</a> 1.1. 指令微调/有监督微调</h3><ul><li>FT (Fine-tuning, 微调)</li><li>SFT（Supervised Fine-tuning, 有监督微调）也被称为指令微调（Instruction Fine-tuning） <ul><li>通过为模型提供特定任务的明确指令或示例来进行微调，通常保持预训练模型的知识</li><li>优点: 专注于特定任务的微调，适应性强，同时保留了模型的基础能力。</li><li>缺点: 可能无法充分挖掘模型在某些高度复杂任务中的潜力。</li></ul></li></ul><h3 id="_1-2-多任务微调-multi-tasking-ft" tabindex="-1"><a class="header-anchor" href="#_1-2-多任务微调-multi-tasking-ft" aria-hidden="true">#</a> 1.2. 多任务微调 Multi-tasking FT</h3><p>多个能力都加强, 把数据都合一起进行训练</p><figure><img src="/blog/assets/015_multi_task_finetune-TK9vK-vK.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_2-模型微调流程" tabindex="-1"><a class="header-anchor" href="#_2-模型微调流程" aria-hidden="true">#</a> 2. 模型微调流程</h2><ul><li>明确问题</li><li>尝试Prompt Engineering是否能解决问题 <ul><li>能用Few-shot尽量用此解决问题，解决不了再考虑用Fine-tune，Fine-tune的模型会在微调的能力上有所提升，但有可能在其他能力上会有所下降。</li><li>Few-shot <ul><li>问题 <ul><li>1.token量增多，context 几乎占满</li><li>2.加入了多个few-shot, 效果仍然不好</li></ul></li></ul></li></ul></li><li>不行的话，采用微调</li><li>选择多个开源模型进行尝试</li><li>分析与预期指标的Gap，缺什么能力</li><li>选择模型 <ul><li>Fine-tuned Model</li></ul></li><li>收集数据</li><li>清洗数据</li><li>指令微调 SFT</li><li>对齐</li><li>Evaluate <ul><li>A/B Test</li></ul></li><li>压缩/量化 &amp; 上线</li><li>基于人类反馈的强化学习（RLHF， Reinforcement Learning from Human Feedback）</li></ul><h2 id="_3-数据构造" tabindex="-1"><a class="header-anchor" href="#_3-数据构造" aria-hidden="true">#</a> 3. 数据构造</h2><p>数据格式跟传统AI不一样，是问答对形式（input, output），其中input部分是Prompt形式 （因为用户使用的时候就是用prompt的形式）</p><ul><li>Input: Prompt=Instruction+input</li><li>Output: output</li></ul><p>json格式</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>{
    &quot;instruction&quot;: &quot;xxx&quot;,
    &quot;input&quot;: &quot;&quot;, // 有时有值，有时没有值
    &quot;output&quot;: &quot;xxx&quot;
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>不需要太多的数据，例如1000条也够了(几千条-几十万条之间)，因为是在已有模型上添加功能，不是从零训练</p><p>Fine-tune过程--划分训练集、验证集和测试集</p><ul><li>训练集：进行训练的数据</li><li>验证集：用于边训练边看效果（月考模考）</li><li>测试集：训练完后最后测试（高考）</li></ul><h2 id="_4-微调策略分类" tabindex="-1"><a class="header-anchor" href="#_4-微调策略分类" aria-hidden="true">#</a> 4. 微调策略分类</h2><h3 id="_4-1-基于微调范围-全量微调和部分参数微调" tabindex="-1"><a class="header-anchor" href="#_4-1-基于微调范围-全量微调和部分参数微调" aria-hidden="true">#</a> 4.1. 基于微调范围：全量微调和部分参数微调</h3><ul><li>全量微调 Full Fine-tuning <ul><li>全部参数都会改变，影响很大，会影响模型之前的能力，不太建议</li><li>优：高度适应特定任务，能够大幅度提高模型的性能</li><li>缺：需要大量计算资源和时间，同时可能导致模型在新任务上泛化能力下降</li></ul></li><li>部分参数微调 Partial Fine-tuning / Freeze Fine-tuning <ul><li>仅微调模型的部分参数（如后期层或特定层），而不是全部参数</li><li>优：计算资源需求较低，过拟合风险较小</li><li>缺：对复杂任务的适应能力可能不如全量微调</li><li>细分 <ul><li>PEFT 参数高效微调 （Parameter-Efficient Fine-Tuning， PEFT） <ul><li>只微调少量或者额外的参数，降低计算、存储成本</li><li>常见方法 <ul><li>适应性微调 Adapter Fine-tuning <ul><li>通过在预训练模型的特定层之间插入小型适应性模块（adapter），仅对这些模块进行微调，而保持主模型参数不变</li><li>优：高效灵活，减少了微调的计算成本和内存占用，适用于多个任务</li></ul></li><li>LoRA（Low-Rank Adaptation） <ul><li>属于适应性微调，微调部分参数，通过低秩矩阵来微调模型参数，这种方法只微调一个较小的参数子集，通常是模型权重矩阵的低秩近似部分。</li><li>最常用，推荐，微调的结果不太影响原有的模型能力</li></ul></li><li>BitFit <ul><li>只微调偏置参数</li></ul></li></ul></li></ul></li><li>选择不同层layer来微调 <ul><li>不建议</li><li>细分 <ul><li>微调后层（Fine-Tuning Last Layers） <ul><li>仅微调模型的最后几层，这种方法适用于希望在保持原模型能力的基础上增加一些特定任务的适应性。</li><li>优：减少了微调的复杂性和资源需求，同时仍然能够提升模型在特定任务上的表现</li><li>缺：微调深度有限，可能无法充分适应任务需求</li></ul></li></ul></li></ul></li></ul></li></ul></li></ul><h4 id="_4-1-1-gpu-显存-计算" tabindex="-1"><a class="header-anchor" href="#_4-1-1-gpu-显存-计算" aria-hidden="true">#</a> 4.1.1. GPU 显存 计算</h4><p>7B</p><ul><li>70亿 * 4 byte <ul><li>70亿参数</li><li>每个参数 4 byte</li><li>计算出总共多少GB，记为 a GB</li></ul></li></ul><p>全量微调 （需要5a GB）</p><ul><li>模型本身 *1</li><li>Gradient *1</li><li>Optimizer States * 2</li><li>变量 *1</li></ul><p>LoRA (略比aGB大，训练的参数都不到原参数量的1%)</p><p>Trainable: 20971520 | total: 7262703616 | Percentage: 0.2888%</p><ul><li>模型本身 *1</li><li>Gradient *1 * 1%</li><li>Optimizer States * 2 * 1%</li></ul><h3 id="_4-2-基于任务-sft-rlhf-rlaif" tabindex="-1"><a class="header-anchor" href="#_4-2-基于任务-sft-rlhf-rlaif" aria-hidden="true">#</a> 4.2. 基于任务：SFT，RLHF，RLAIF</h3><ul><li>监督式微调SFT( Supervised Fine Tuning);</li><li>基于人类反馈的强化学习微调RLHF(把人类的反馈通过强化学习的方式，引入到大模型的微调中)；</li><li>基于AI反馈的强化学习微调RLAIF（人类反馈成本高）</li></ul><h3 id="_4-3-低资源微调" tabindex="-1"><a class="header-anchor" href="#_4-3-低资源微调" aria-hidden="true">#</a> 4.3. 低资源微调</h3><ul><li>LoRA/QLoRA(减少训练参数)</li><li>混合精度训练(减少显存占用一半，加速训练一倍)</li><li>LOMO(大幅减少显存占用，某些场景比lora差)</li><li>Activation checkpointing(减少显存占用，额外计算量)</li><li>异构设备训练(减少显存占用)</li></ul><h3 id="_4-4-deepspeed" tabindex="-1"><a class="header-anchor" href="#_4-4-deepspeed" aria-hidden="true">#</a> 4.4. deepspeed</h3><p>分布式训练</p><ul><li>数据分区：数据太大，放不到一个显存中</li><li>模型分区：模型太大，放不到一个显存中</li></ul><p>deepspeed将模型分区放到不同显存中处理，进行显存间的通信，为了解决极端显存不够用的情形，也可能短时间内将模型放在内存中（offload）处理</p><h2 id="_5-lora-与-qlora" tabindex="-1"><a class="header-anchor" href="#_5-lora-与-qlora" aria-hidden="true">#</a> 5. LoRA 与 QLoRA</h2><h3 id="_5-1-lora" tabindex="-1"><a class="header-anchor" href="#_5-1-lora" aria-hidden="true">#</a> 5.1. LoRA</h3><p>Paper Name: LoRA: Low-Rank Adaptation of Large Language Models</p><p>Paper：https://arxiv.org/abs/2106.09685</p><p>W + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span></span></span></span> W = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">W&#39;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></p><p>微调改变了模型的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span></span></span></span> W参数, W冻结不变</p><p>LoRA的应用可以发生在模型里面的任何线性转换上</p><ul><li>h= Wx (线性转换 Linear)</li><li>h = (W + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span></span></span></span> W)x</li></ul><p>LoRA优势</p><ul><li>训练参数减少，参数变动减小（要冻结原有参数） <ul><li>如果参数改动很大，原有能力变化会很大，希望对原有参数改动比较小</li><li>推理阶段需要将原有参数和训练出的参数合并进行推理</li></ul></li><li>训练所需显存降低</li><li>训练效率提高</li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>lora_config = LoraConfig(
    r=8, # lora rank, Low Rank 低秩矩阵，rank 通常选8或16 
    lora_alpha=32, # 新的W = 旧的W + lora_alpha/r * $\Delta$ W (影响 lora 更新权重占比)  
    target_modules=modules, # 需要进行lora训练的Linear,一般情况不会把所有Linear都进行lora的训练，而是选2-3个，更多是对qkv矩阵做lora训练
    lora_dropout=0.05,
    bias=&quot;none&quot;,
    task_type=&quot;CAUSAL_LM&quot;
)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-2-qlora" tabindex="-1"><a class="header-anchor" href="#_5-2-qlora" aria-hidden="true">#</a> 5.2. QLoRA</h3><p>大模型的加载（将模型导入显存）</p><p>量化：大模型导入之前做量化，如将32bit-&gt;4bit导入</p><p>量化解决显存不够的情形，但精度下降，会影响模型的效果</p><p>QLoRA 来加载模型，进行量化，来降低显存的消耗</p><h2 id="_6-微调实践" tabindex="-1"><a class="header-anchor" href="#_6-微调实践" aria-hidden="true">#</a> 6. 微调实践</h2><h3 id="_6-1-3个关键部分" tabindex="-1"><a class="header-anchor" href="#_6-1-3个关键部分" aria-hidden="true">#</a> 6.1. 3个关键部分</h3><ul><li>模型（从Huggingface上找） <ul><li>tokenizer：token和id的mapping</li><li>model</li></ul></li><li>数据（从Huggingface上找）</li><li>参数</li></ul><h3 id="_6-2-微调高级设置" tabindex="-1"><a class="header-anchor" href="#_6-2-微调高级设置" aria-hidden="true">#</a> 6.2. 微调高级设置</h3><ul><li>量化等级（QLoRA） <ul><li>4或8 bit</li><li>使用量化，模型会变小，精度也 会变小，效果会稍微下降一点</li></ul></li><li>加速方式 <ul><li>flash-attention</li></ul></li><li>训练方式 <ul><li>SFT (Supervised Fine-Tuning) 指令微调 （70%-80%采用此）</li><li>对齐常见2种方式 <ul><li>PPO （强化学习方式）</li><li>DPO</li></ul></li></ul></li><li>数据集 <ul><li>本地数据集</li><li>来自HuggingFace的数据集</li></ul></li><li>LoRA参数 <ul><li>LoRA矩阵的秩大小 <ul><li>通常选8（或者16）</li></ul></li><li>LoRA缩放系数 <ul><li>通常是LoRA秩的2倍，16或32</li></ul></li></ul></li></ul><h3 id="_6-3-github-tloen-alpaca-lora" tabindex="-1"><a class="header-anchor" href="#_6-3-github-tloen-alpaca-lora" aria-hidden="true">#</a> 6.3. github: tloen/alpaca-lora</h3><p>Github: https://github.com/tloen/alpaca-lora</p><p>训练</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python finetune.py \
    --base_model &#39;decapoda-research/llama-7b-hf&#39; \ # 基础模型
    --data_path &#39;yahma/alpaca-cleaned&#39; \ # 数据集
    --output_dir &#39;./lora-alpaca&#39; \ # 微调模型输出路径
    --batch_size 128 \ # 此行及之下都是参数
    --micro_batch_size 4 \
    --num_epochs 3 \
    --learning_rate 1e-4 \
    --cutoff_len 512 \
    --val_set_size 2000 \
    --lora_r 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --lora_target_modules &#39;[q_proj,v_proj]&#39; \
    --train_on_inputs \
    --group_by_length
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>推理</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python generate.py \
    --load_8bit \
    --base_model &#39;decapoda-research/llama-7b-hf&#39; \ # 原有参数
    --lora_weights &#39;tloen/alpaca-lora-7b&#39; # 新的参数
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_6-4-llama-factory" tabindex="-1"><a class="header-anchor" href="#_6-4-llama-factory" aria-hidden="true">#</a> 6.4. LLaMA-Factory</h3><p>LLaMA-Factory 微调UI界面，将各种模型和参数的配置进行了封装，简化了代码编写流程，只需在UI界面上进行选择和配置内容即可开始微调，无需写代码，除非一些新出的模型，还没有集成到LLaMA-Factory时，可以自己写代码</p><h3 id="_6-5-more" tabindex="-1"><a class="header-anchor" href="#_6-5-more" aria-hidden="true">#</a> 6.5. More</h3><p>租GPU</p><ul><li>国内：AutoDL</li><li>国外：jarvislabs.ai</li></ul><p>llama模型参数下载: https://github.com/shawwn/llama-dl</p><p>https://github.com/ymcui/Chinese-LLaMA-Alpaca</p><p>https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese</p><h2 id="_7-开源模型" tabindex="-1"><a class="header-anchor" href="#_7-开源模型" aria-hidden="true">#</a> 7. 开源模型</h2><figure><img src="/blog/assets/015_basic_llm-CfFnBlay.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>英文开源模型：</p><ul><li>llama <ul><li>由Meta公司推出的大型语言模型系列</li></ul></li><li>alpaca:由斯坦福大学基于LLAMA模型开发和训练的一个轻量化、成本低的指令微调模型，使得Alpaca在较小的资源下能够完成特定的任务。</li><li>Mistral-7B <ul><li>https://colab.research.google.com/drive/1TVEd2fj3YiklvX5zOqJxQAmXnLOk6-to?usp=sharing#scrollTo=7St-hFLNmS2v</li></ul></li><li>Mixture of Experts (MoE) 之 Mistral 8x7B 混合专家 <ul><li>https://colab.research.google.com/drive/1VDa0lIfqiwm16hBlIlEaabGVTNB3dN1A?usp=sharing#scrollTo=lChdRaiR81Dc</li></ul></li></ul><p>中文开源模型：</p><ul><li>Qwen</li><li>ChatGLM <ul><li>微调主要是6B为主，没有开源更大的模型</li><li>chatglm.cpp是用c++重新写了一遍，目标是能把模型跑在CPU上；现在基本上每个模型都有对应的cpp版本（量化加速推理方案）</li></ul></li></ul><p>全开源 (给了数据集和权重参数,上述没有给出数据集)：</p><ul><li>Pythia <ul><li>https://github.com/EleutherAI/pythia</li></ul></li><li>OLMo <ul><li>https://github.com/allenai/OLMo</li></ul></li></ul><h3 id="_7-1-mistral-7b" tabindex="-1"><a class="header-anchor" href="#_7-1-mistral-7b" aria-hidden="true">#</a> 7.1. Mistral-7B</h3><ul><li>使用滑动窗口注意力以应对长序列 Sliding Window Attention（SWA）</li><li>使用Grouped-query attention（GQA）以加速推理 <img src="/blog/assets/015_sliding_window_attention-jXX1GIf7.png" alt="" loading="lazy"></li></ul><figure><img src="/blog/assets/015_mistral_structure-Fl6s4WOT.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_8-混合专家模型-moe-mixture-of-experts" tabindex="-1"><a class="header-anchor" href="#_8-混合专家模型-moe-mixture-of-experts" aria-hidden="true">#</a> 8. 混合专家模型 MoE，Mixture of Experts</h2><p>Paper Name: Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</p><p>Paper: https://arxiv.org/pdf/2101.03961</p><figure><img src="/blog/assets/015_moe_structure-vlzoKbsv.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/blog/assets/015_switching_ffn_layer-2nh8QQUw.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>多个专家 <ul><li>Mistral 8x7B有8个专家</li><li>deepseek的MoE有160个专家</li></ul></li><li>每个专家有自己的专长</li><li>Router 路由选择 <ul><li>softmax 得到每个专家的权重占比</li></ul></li><li>sparse 稀疏混合专家 <ul><li>每次无需问所有专家，只是选择其中几个来问</li><li>Mistral 7B是稀疏混合专家模型</li></ul></li><li>多个共享一些模块，部分模块是分开的 <ul><li>Mistral 8x7B 按理有56B 但有些共享模块，所以总共约40B</li></ul></li><li>MoE用switching FFN layer 替代原来的 FFN，其他不变，也就是其他模块共享 <ul><li>MoE该层由一个门控网络和一定数量的专家网络组成。</li></ul></li></ul><p>尽管与稠密模型相比，MoE 它具有高效预训练和快速推理的优点，但也面临着一些挑战：</p><ul><li><p>训练:MoE 预训练的计算效率可以大大提高，但在微调过程中很难实现泛化，导致过拟合。</p></li><li><p>推理:虽然 MoE 可能有很多参数，但只有一部分是在推理过程中使用的。推理速度比参数相同的稠密模型快得多。然而，所有参数都需要加载 RAM 因此，对内存的要求很高。</p></li></ul><p>MOE的优势</p><ul><li>计算效率：通过稀疏选择机制，MOE架构避免了让所有专家都参与推理，降低了计算复杂度。实际中，MOE架构的计算量可以近似为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo>⋅</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k⋅n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>，其中k kk是激活的专家数量，n nn是输入序列长度。</li><li>扩展性：MOE非常适合大规模模型。通过增加专家数量，可以扩大模型容量，而不显著增加每次推理的计算成本。这使得MOE特别适合用于超大规模语言模型，如Switch Transformer、GShard等。</li><li>灵活性：MOE能够根据输入动态选择专家，因此它具有灵活的模型结构，可以处理不同类型的任务和数据。</li></ul><p>MOE通过以下几方面的设计来提升模型性能和效率：</p><ul><li>稀疏选择专家，降低计算复杂度</li><li>门控网络根据输入动态选择专家</li><li>负载均衡损失确保专家均衡利用</li></ul><h2 id="_9-rlhf-基于人类反馈的强化学习" tabindex="-1"><a class="header-anchor" href="#_9-rlhf-基于人类反馈的强化学习" aria-hidden="true">#</a> 9. RLHF 基于人类反馈的强化学习</h2><p>RLHF（Reinforcement Learning from Human Feedback）是一种结合了强化学习和人类反馈的机器学习方法，通过直接从人类反馈中学习，使模型更好的适应特定的任务和预期行为。</p><p>要解决的问题：</p><ul><li>传统强化学习的奖励工程（reward engineering）困难和缺少高质量反馈</li><li>在许多复杂任务中，定义一个精确的奖励函数非常困难</li><li>和复杂的人类价值观对齐 <ul><li>如何评价GPT生成的文本好不好呢？好的定于是基于人类价值观的，如何让GPT学到人类的价值观呢？</li></ul></li></ul><p>主要原理:RLHF主要包括四个组件</p><ul><li>预训练模型（pre-trained model）：开始于一个预训练模型，如在大量文本数据上预训练的大语言模型</li><li>人类反馈（human feedback):收集关于模型输出质量的人类反馈，这些反馈可以能包括对生成的文本进行标注或者评分，并提供改进的指导。</li><li>奖励建模（reward modeling）：使用人类反馈来训练一个奖励模型，这个奖励模型学习根据人类反馈来给模型生成的输出评分。 <ul><li>RM 奖励模型/偏好模型</li></ul></li><li>强化学习（reinforcement learning）：利用奖励模型作为奖励函数，使用标准的强化学习或者深度学习算法来继续训练原始模型，优化模型的输出以最大化奖励模型给出的分数。</li></ul><h2 id="_10-references" tabindex="-1"><a class="header-anchor" href="#_10-references" aria-hidden="true">#</a> 10. References</h2><ul><li><a href="https://towardsdatascience.com/mixtral-8x7b-understanding-and-running-the-sparse-mixture-of-experts-0e3fc7fde818" target="_blank" rel="noopener noreferrer">Mixtral-8x7B: Understanding and Running the Sparse Mixture of Experts<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a aria-label="多模态大模型" class="vp-link nav-link prev nav-link prev" href="/blog/zh/posts/llm/016_multimodal.html"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>多模态大模型</div></a><a aria-label="RAG评估指标" class="vp-link nav-link next nav-link next" href="/blog/zh/posts/llm/014_rag_evaluation.html"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">RAG评估指标<span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><!----></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-fX15qMK8.js" defer></script>
  </body>
</html>
